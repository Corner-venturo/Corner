#!/usr/bin/env node
/**
 * Venturo Database Migration Tool
 *
 * é€™å€‹è…³æœ¬æœƒè‡ªå‹•åŸ·è¡ŒæœªåŸ·è¡Œçš„ migration æª”æ¡ˆ
 * ä½¿ç”¨ Supabase Management APIï¼Œç¢ºä¿åœ¨ä»»ä½•é›»è…¦ä¸Šéƒ½èƒ½æ­£å¸¸å·¥ä½œ
 *
 * ä½¿ç”¨æ–¹å¼ï¼š
 *   node scripts/db-migrate.js
 */

const https = require('https')
const fs = require('fs')
const path = require('path')

const SUPABASE_ACCESS_TOKEN = 'sbp_94746ae5e9ecc9d270d27006ba5ed1d0da0bbaf0'
const PROJECT_REF = 'pfqvdacxowpgfamuvnsn'
const MIGRATIONS_DIR = path.join(__dirname, '../supabase/migrations')

/**
 * åŸ·è¡Œ SQL æŸ¥è©¢
 */
async function executeSQL(sql, description = 'SQL') {
  return new Promise((resolve, reject) => {
    const options = {
      hostname: 'api.supabase.com',
      port: 443,
      path: `/v1/projects/${PROJECT_REF}/database/query`,
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${SUPABASE_ACCESS_TOKEN}`,
        'Content-Type': 'application/json'
      }
    }

    const postData = JSON.stringify({ query: sql })

    const req = https.request(options, (res) => {
      let data = ''

      res.on('data', (chunk) => {
        data += chunk
      })

      res.on('end', () => {
        if (res.statusCode === 200 || res.statusCode === 201) {
          console.log(`âœ… ${description} åŸ·è¡ŒæˆåŠŸ`)
          resolve({ success: true, data })
        } else {
          console.error(`âŒ ${description} åŸ·è¡Œå¤±æ•— (${res.statusCode})`)
          console.error('å›æ‡‰:', data)
          reject(new Error(`HTTP ${res.statusCode}: ${data}`))
        }
      })
    })

    req.on('error', (error) => {
      console.error(`âŒ ç¶²è·¯éŒ¯èª¤:`, error.message)
      reject(error)
    })

    req.write(postData)
    req.end()
  })
}

/**
 * æª¢æŸ¥ migration è¨˜éŒ„è¡¨æ˜¯å¦å­˜åœ¨
 */
async function ensureMigrationTable() {
  const sql = `
    CREATE TABLE IF NOT EXISTS public._migrations (
      id serial PRIMARY KEY,
      name text NOT NULL UNIQUE,
      executed_at timestamp with time zone DEFAULT now()
    );
  `

  try {
    await executeSQL(sql, 'å»ºç«‹ migration è¨˜éŒ„è¡¨')
    return true
  } catch (error) {
    console.error('ç„¡æ³•å»ºç«‹ migration è¡¨:', error.message)
    return false
  }
}

/**
 * å–å¾—å·²åŸ·è¡Œçš„ migrations
 */
async function getExecutedMigrations() {
  const sql = `SELECT name FROM public._migrations ORDER BY executed_at;`

  try {
    const result = await executeSQL(sql, 'æŸ¥è©¢å·²åŸ·è¡Œçš„ migrations')
    const data = JSON.parse(result.data)
    return data.map(row => row.name)
  } catch (error) {
    console.warn('âš ï¸ ç„¡æ³•æŸ¥è©¢ migrationsï¼Œå¯èƒ½æ˜¯ç¬¬ä¸€æ¬¡åŸ·è¡Œ')
    return []
  }
}

/**
 * è¨˜éŒ„å·²åŸ·è¡Œçš„ migration
 */
async function recordMigration(name) {
  const sql = `INSERT INTO public._migrations (name) VALUES ('${name}');`
  await executeSQL(sql, `è¨˜éŒ„ migration: ${name}`)
}

/**
 * è®€å–æ‰€æœ‰ migration æª”æ¡ˆ
 */
function getMigrationFiles() {
  if (!fs.existsSync(MIGRATIONS_DIR)) {
    console.log('âš ï¸ migrations ç›®éŒ„ä¸å­˜åœ¨')
    return []
  }

  return fs.readdirSync(MIGRATIONS_DIR)
    .filter(file => file.endsWith('.sql'))
    .sort()
}

/**
 * ä¸»åŸ·è¡Œå‡½æ•¸
 */
async function main() {
  console.log('ğŸ”„ Venturo Database Migration Tool\n')
  console.log(`ğŸ“‚ Migrations ç›®éŒ„: ${MIGRATIONS_DIR}`)
  console.log(`ğŸ—„ï¸  Project: ${PROJECT_REF}\n`)

  // 1. ç¢ºä¿ migration è¨˜éŒ„è¡¨å­˜åœ¨
  const tableCreated = await ensureMigrationTable()
  if (!tableCreated) {
    console.error('\nâŒ ç„¡æ³•å»ºç«‹ migration è¨˜éŒ„è¡¨ï¼Œè«‹æª¢æŸ¥æ¬Šé™')
    process.exit(1)
  }

  // 2. å–å¾—å·²åŸ·è¡Œçš„ migrations
  const executedMigrations = await getExecutedMigrations()
  console.log(`\nğŸ“Š å·²åŸ·è¡Œçš„ migrations: ${executedMigrations.length} å€‹`)
  if (executedMigrations.length > 0) {
    executedMigrations.forEach(name => console.log(`  âœ“ ${name}`))
  }

  // 3. å–å¾—æ‰€æœ‰ migration æª”æ¡ˆ
  const allMigrations = getMigrationFiles()
  console.log(`\nğŸ“‹ Migration æª”æ¡ˆç¸½æ•¸: ${allMigrations.length} å€‹`)

  // 4. æ‰¾å‡ºæœªåŸ·è¡Œçš„ migrations
  const pendingMigrations = allMigrations.filter(
    file => !executedMigrations.includes(file)
  )

  if (pendingMigrations.length === 0) {
    console.log('\nâœ… æ‰€æœ‰ migrations éƒ½å·²åŸ·è¡Œï¼Œè³‡æ–™åº«æ˜¯æœ€æ–°ç‹€æ…‹ï¼')
    process.exit(0)
  }

  console.log(`\nğŸ”„ å¾…åŸ·è¡Œçš„ migrations: ${pendingMigrations.length} å€‹`)
  pendingMigrations.forEach(name => console.log(`  â€¢ ${name}`))

  // 5. åŸ·è¡ŒæœªåŸ·è¡Œçš„ migrations
  let successCount = 0
  let failCount = 0

  for (const migrationFile of pendingMigrations) {
    console.log(`\nğŸ“ åŸ·è¡Œ: ${migrationFile}`)

    const filePath = path.join(MIGRATIONS_DIR, migrationFile)
    const sql = fs.readFileSync(filePath, 'utf8')

    try {
      await executeSQL(sql, migrationFile)
      await recordMigration(migrationFile)
      successCount++
    } catch (error) {
      console.error(`âŒ Migration å¤±æ•—:`, error.message)
      failCount++
      // é‡åˆ°éŒ¯èª¤æ™‚åœæ­¢åŸ·è¡Œå¾ŒçºŒ migrations
      break
    }
  }

  // 6. é¡¯ç¤ºçµæœ
  console.log('\n' + '='.repeat(50))
  console.log(`âœ… æˆåŠŸ: ${successCount} å€‹`)
  console.log(`âŒ å¤±æ•—: ${failCount} å€‹`)

  if (failCount > 0) {
    console.log('\nâš ï¸ éƒ¨åˆ† migration åŸ·è¡Œå¤±æ•—ï¼Œè«‹æª¢æŸ¥éŒ¯èª¤è¨Šæ¯')
    process.exit(1)
  } else {
    console.log('\nğŸ‰ æ‰€æœ‰ migrations åŸ·è¡Œå®Œæˆï¼')
    process.exit(0)
  }
}

// åŸ·è¡Œä¸»å‡½æ•¸
main().catch(error => {
  console.error('\nâŒ åŸ·è¡ŒéŒ¯èª¤:', error.message)
  process.exit(1)
})
